{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6860986547085202\n"
     ]
    }
   ],
   "source": [
    "#Step 1: Let's begin by imporing the necessary packages\n",
    "\n",
    "from scipy.spatial.distance import euclidean as euc\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Step 2: Setting up a class for our K-Nearest-Neighbour algorithm and the relevant formulas\n",
    "\n",
    "class KNN():\n",
    "    \n",
    "    #No need to modify the __init__ method.\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"Function that stores the trainning data (X_train) and it's corresponding labels (y_train).\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def _get_distances(self, x):\n",
    "        \"\"\"Function that calculates each distance between an unlabelled data point and each point in the trainning\n",
    "        data and subsequently appends such distance, along with an index into a distances list.\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        for ind, val in enumerate(self.X_train): #the loop is ennumerated pair the distances with an index for storage.\n",
    "            dist_to_i = euc(x, val) #calculating the eucledian distance.\n",
    "            distances.append((ind, dist_to_i))\n",
    "        return distances\n",
    "       \n",
    "    def _get_k_nearest(self, dists, k):\n",
    "        \"\"\"Function that sorts the collection of distances from smallest to largest (in ascending order) and\n",
    "        picks the first K entries from the sorted collection.\n",
    "        \"\"\"\n",
    "        sorted_dists = sorted(dists, key=lambda x: x[1]) #sorting on the distances column.\n",
    "        return sorted_dists[:k]\n",
    "    \n",
    "    def _get_label_prediction(self, k_nearest):\n",
    "        \"\"\"Function that will get the labels that correspond to each of the k-nearest point, and return the \n",
    "        most common label amongst the neighbours.\n",
    "        \"\"\"\n",
    "        labels = [self.y_train[i] for i, _ in k_nearest] #creating a list of labels from the labelled data (y_train)\n",
    "        #for each index in k-nearest.\n",
    "        counts = np.bincount(labels) #total counts for each label\n",
    "        return np.argmax(counts)\n",
    "    \n",
    "    def predict(self, X_test, k=3):\n",
    "        \"\"\"Function that when inputed an array of unlabelled data (X_test), calculates a prediction for \n",
    "        each point and returns an array of predictions. \n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for i in X_test:\n",
    "            dists = self._get_distances(i) #calculating the distance between each unlabelled and labelled point.\n",
    "            k_nearest = self._get_k_nearest(dists, k) #identifying nearest points to the unlabelled data point.\n",
    "            predicted_label = self._get_label_prediction(k_nearest) #determinning the most common label amongst KNN.\n",
    "            preds.append(predicted_label)\n",
    "        return preds\n",
    "\n",
    "#Step 3: Initiating the KNN class and adding it the corresponding attributes and assigning it the relevant functions.\n",
    "\n",
    "knn = KNN()\n",
    "knn.fit\n",
    "knn._get_distances\n",
    "knn._get_label_prediction\n",
    "knn.predict\n",
    "\n",
    "#Step 4: Importing and cleaning the data\n",
    "\n",
    "raw_df = pd.read_csv('titanic.csv')\n",
    "df = raw_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=False)\n",
    "df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "df['Age'] = df['Age'].fillna(value=df['Age'].median())\n",
    "df = df.dropna()\n",
    "one_hot_df = pd.get_dummies(df)\n",
    "labels = one_hot_df['Survived']\n",
    "one_hot_df.drop('Survived', axis=1, inplace=True)\n",
    "one_hot_df = np.array(one_hot_df)\n",
    "labels = np.array(labels)\n",
    "\n",
    "#Step 5: Splitting our date into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(one_hot_df, labels, test_size=0.25)\n",
    "\n",
    "#Step 6: Testing our KNN classifier\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "preds = knn.predict(X_test, k=3)\n",
    "print(\"Testing Accuracy: {}\".format(accuracy_score(y_test, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
